## ğŸ“¦  **Roadmap, Phases, Architecture & Tasks**
**File name:** `comic_upscale_roadmap.md`  
_(Copyâ€‘paste the whole block into your IDE â€“ the LLM â€œassistantâ€ will treat it as a single source.)_

---  

```markdown
# Comic Upscale â€“ Endâ€‘toâ€‘End Roadmap
> Goal: Upscale 2â€¯000â€“10â€¯000 daughterâ€‘comic images (512Ã—768 â†’ 2Ã—â€‘2.5Ã—) on a **free** GPU instance (vast.ai), store results, and monitor progress via a tiny Flask admin UI backed by SQLite.

---

## ğŸ¯ Highâ€‘Level Objectives
| # | Objective |
|---|-----------|
| 1 | Choose a **free, permissivelyâ€‘licensed** upscaling model (Realâ€‘ESRGAN). |
| 2 | Build a **single Docker image** that contains: <br>â€¢ CUDA runtime + PyTorch <br>â€¢ Realâ€‘ESRGAN python wrapper <br>â€¢ Async upscaling script <br>â€¢ Flask admin UI + SQLite DB |
| 3 | Automate the flow: **SCP â†’ unpack â†’ launch script â†’ queue â†’ upscale â†’ store â†’ UI**. |
| 4 | Keep **cloud cost â‰¤â€¯0.15â€¯USD** per full run (stop the instance ASAP). |
| 5 | Produce clean, reproducible artefacts for later LoRA fineâ€‘tuning. |

---

## ğŸ—‚ï¸ Development Phases & Milestones

| Phase | Main Deliverable | Rough Duration* | Key Tasks |
|-------|------------------|-----------------|-----------|
| **0 â€“ Prep** | Repo skeleton, local test data | 0.5â€¯d | â€¢ Create repo <br>â€¢ Collect 20â€‘30 sample images (photo, anime, 3â€‘D) |
| **1 â€“ Model & Base Image** | Dockerfile that builds on `nvidia/cuda` and installs Realâ€‘ESRGAN | 1â€¯d | â€¢ Choose CUDA version (12.1) <br>â€¢ `pip install realesrgan torch torchvision` <br>â€¢ Verify `realesrgan.fetch_models()` works |
| **2 â€“ Upscale Engine** | `upscale.py` â€“ async queue, DB writeâ€‘back, multiâ€‘worker | 1.5â€¯d | â€¢ Design SQLite schema (`ImageJob`) <br>â€¢ Implement `save_job / update_job` helpers <br>â€¢ Use `asyncio.Queue` + `ThreadPoolExecutor` for GPU work <br>â€¢ Add CLI flags (`--scale`, `--workers`, `--input`, `--output`) |
| **3 â€“ Flask Admin** | Minimal darkâ€‘theme admin with login, progress table, download button | 1â€¯d | â€¢ Flaskâ€‘Login + SQLAlchemy models (`User`, `ImageJob`) <br>â€¢ Routes: `/login`, `/`, `/download/<id>` <br>â€¢ Nonâ€‘standard port **5800** <br>â€¢ Simple CSS dark theme |
| **4 â€“ Integration** | Dockerâ€‘composeâ€‘like entrypoint that starts both services (Gunicorn + background script) | 0.5â€¯d | â€¢ `docker run` command that mounts three persistent volumes (`/data/input`, `/data/output`, `/data/db`) <br>â€¢ `CMD ["sh","-c","python /app/upscale.py â€¦ & gunicorn â€¦"]` |
| **5 â€“ Deployment Scripts** | Bash wrappers for SCP, start/stop, autoâ€‘shutdown | 0.5â€¯d | â€¢ `upload.sh` â€“ compress â†’ scp â†’ remote `tar` <br>â€¢ `run_upscale.sh` â€“ `docker exec -d â€¦` <br>â€¢ `idle_watchdog.sh` â€“ kills container after 5â€¯min idle |
| **6 â€“ Costâ€‘Control & Monitoring** | Autoâ€‘shutdown, logging, simple cost estimate | 0.5â€¯d | â€¢ Add `docker stats`â€‘based watchdog (GPU utilization <â€¯5â€¯% â†’ stop) <br>â€¢ Log to `/app/logs/upscale.log` <br>â€¢ Write a oneâ€‘liner to compute USD cost (`$0.04/hr`) |
| **7 â€“ Final QA** | Endâ€‘toâ€‘end test on a remote instance, documentation | 0.5â€¯d | â€¢ Run on a **T4** instance (â‰ˆ30â€¯min for 4â€¯000 images) <br>â€¢ Verify DB counts, UI refresh, download works <br>â€¢ Write `README.md` with oneâ€‘click commands |
| **Total** | **â‰ˆâ€¯6â€¯days** (including buffer) | | |

*Durations assume a single developer working partâ€‘time; adjust as needed.*

---

## ğŸ—ï¸ Architecture Overview  

```mermaid
graph TD
    A[Client PC] -->|scp tar.gz| B[vast.ai VM]
    B --> C[Docker Engine]
    C -->|mount| D[/data/input]
    C -->|mount| E[/data/output]
    C -->|mount| F[/data/db]
    subgraph Container
        G[upscale.py] -->|writes| H[SQLite DB]
        G -->|produces| I[Upscaled PNGs]
        J[Flask (Gunicorn)] -->|reads| H
        J -->|serves| K[Admin UI (port 5800)]
    end
    K --> L[User (browser)]
    I -->|download| L
```

*All three volumes (`input`, `output`, `db`) persist across container restarts and VM reâ€‘boots.*  

---

## ğŸ“‹ Detailed Task List  

| ID | Description | Owner | Status |
|----|-------------|-------|--------|
| **0** | Initialise Git repo (`github.com/you/comic_upscale`) | â€“ | âœ… |
| **1** | Write `Dockerfile` (base: `nvidia/cuda:12.1-runtime-ubuntu22.04`) | â€“ | âœ… |
| **2** | Add `requirements.txt` (torchâ€‘cu118, realesrgan, Flask, SQLAlchemy, gunicorn, aiofiles) | â€“ | âœ… |
| **3** | Implement SQLite schema (`User`, `ImageJob`) in `flask/models.py` | â€“ | âœ… |
| **4** | Build Flask auth (Login, password hash) | â€“ | âœ… |
| **5** | Create basic dark CSS theme (`static/css/dark-theme.css`) | â€“ | âœ… |
| **6** | Write `upscale.py` (async queue, DB callbacks, error handling) | â€“ | âœ… |
| **7** | Add CLI flags & sanity checks (`--scale 2.5`, `--workers 4`) | â€“ | âœ… |
| **8** | Test Realâ€‘ESRGAN locally on a few images (2Ã—, 2.5Ã—) | â€“ | â¬œ |
| **9** | Implement `upload.sh` (tar, scp, remote `mkdir`, `tar -xz`) | â€“ | âœ… |
| **10** | Write `run_upscale.sh` (docker exec background) | â€“ | âœ… |
| **11** | Write `idle_watchdog.sh` (monitor GPU%, stop container) | â€“ | âœ… |
| **12** | Compose entrypoint (`sh -c "python /app/upscale.py â€¦ & gunicorn â€¦"`) | â€“ | âœ… |
| **13** | Add nonâ€‘standard ports: Flask **5800**, optional REST upscaler **5900** | â€“ | âœ… |
| **14** | Deploy to a **T4** instance on vast.ai (12â€¯GB RAM, 2 vCPU) | â€“ | â¬œ |
| **15** | Run endâ€‘toâ€‘end test (4â€¯000 images) â€“ record time & cost | â€“ | â¬œ |
| **16** | Write README with oneâ€‘click commands (`docker run â€¦`) | â€“ | âœ… |
| **17** | Tag Docker image (`yourname/comic_upscale:latest`) and push to Docker Hub | â€“ | â¬œ |
| **18** | (Optional) Add WebSocket progress bar via Flaskâ€‘SocketIO | â€“ | â¬œ |

*âœ… â€“ Done, ğŸŸ¡ â€“ In progress, â¬œ â€“ Toâ€‘do.*

---

## ğŸ“¦ Docker Image Summary  

| Layer | Content |
|-------|----------|
| **Base** | `nvidia/cuda:12.1-runtime-ubuntu22.04` (CUDAâ€¯12.1, cuDNNâ€¯8) |
| **OS Packages** | `python3-pip git ffmpeg libglib2.0-0` |
| **Python** | `torch==2.2.0+cu118`, `torchvision==0.17.0+cu118`, `realesrgan==0.2.5`, `Flask`, `SQLAlchemy`, `gunicorn`, `aiofiles`, `tqdm` |
| **Model Files** | Downloaded on image build (`realesrgan.fetch_models('weights')`) |
| **App Code** | `upscale.py`, `flask/` (templates + static), `db.py`, `utils.py` |
| **Entry Point** | `CMD ["sh","-c","python /app/upscale.py --input /app/data/input --output /app/data/output --scale 2.5 --workers 4 & gunicorn --bind 0.0.0.0:5800 flask.app:app"]` |

---

## ğŸš¨ Security & Port Considerations  

* **Nonâ€‘standard ports** â€“ Flask UI runs on **5800**, optional healthâ€‘check API on **5900**.  
* **Authentication** â€“ simple username/password stored hashed in SQLite (`admin / <yourâ€‘pass>`).  
* **Network exposure** â€“ only open ports `5800` and `5900` in the vast.ai firewall; all other ports blocked.  
* **Secret handling** â€“ keep `FLASK_SECRET_KEY` and admin password as **environment variables** (`-e`) when launching the container; do **not** hardâ€‘code them.  

---

## ğŸ“ˆ Costâ€‘Control Checklist  

| Item | Recommended Setting |
|------|---------------------|
| GPU type | **T4** (â‰ˆâ€¯$0.04/hr) â€“ good balance of price vs. VRAM (16â€¯GB) |
| vCPU | 2 |
| RAM | 12â€¯GB |
| Disk | 30â€¯GB SSD (enough for input + upscaled) |
| Autoâ€‘shutdown | Use `idle_watchdog.sh` (stop when GPUâ€¯<â€¯5â€¯% for 5â€¯min) |
| Billing estimate | 0.5â€¯hr run â†’ **$0.02**; 2â€¯hr run â†’ **$0.08** â€“ well under $0.15 |

---

## ğŸ“š Next Steps  

1. **Fork / clone** the repo and create the `Dockerfile` using the specifications above.  
2. Build locally, verify Realâ€‘ESRGAN works on a handful of images.  
3. Implement `upscale.py` (Phaseâ€¯2) â€“ test with `--workers 2`.  
4. Add Flask admin (Phaseâ€¯3) â€“ check DB updates in real time.  
5. Push the image to Docker Hub (or GitHub Packages).  
6. Spin up a **T4** instance on vast.ai, mount volumes, run container.  
7. Run `run_upscale.sh`, watch UI at `http://<IP>:5800`.  
8. Once verified, scale to the full dataset and record cost.  

Good luck â€“ the whole pipeline should be runnable with a **single Docker run command** after the first build! ğŸ‰  

---  

*End of `comic_upscale_roadmap.md`*  

